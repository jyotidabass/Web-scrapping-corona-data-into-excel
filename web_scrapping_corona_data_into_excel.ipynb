{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "web scrapping corona data into excel.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNJycN9Zy0T2SE5HqG57Ap+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jyotidabass/Web-scrapping-corona-data-into-excel/blob/main/web_scrapping_corona_data_into_excel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6DfSElEXDIq",
        "outputId": "09ccb699-0eee-4001-b7c5-11bab96f429f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests) (3.0.4)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (4.2.6)\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.7/dist-packages (0.0.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from bs4) (4.6.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install requests\n",
        "!pip install lxml\n",
        "!pip install bs4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required modules\n",
        "import requests\n",
        "import bs4\n",
        "import pandas as pd\n",
        " \n",
        " \n",
        " \n",
        "# Make requests from webpage\n",
        "url = 'https://www.worldometers.info/coronavirus/country/india/'\n",
        "result = requests.get(url)\n",
        " \n",
        " \n",
        " \n",
        "# Creating soap object\n",
        "soup = bs4.BeautifulSoup(result.text,'lxml')\n",
        " \n",
        " \n",
        " \n",
        "# Searching div tags having maincounter-number class\n",
        "cases = soup.find_all('div' ,class_= 'maincounter-number')\n",
        " \n",
        " \n",
        " \n",
        "# List to store number of cases\n",
        "data = []\n",
        " \n",
        "# Find the span and get data from it\n",
        "for i in cases:\n",
        "    span = i.find('span')\n",
        "    data.append(span.string)\n",
        " \n",
        "# Display number of cases\n",
        "print(data)\n",
        " \n",
        " \n",
        "   \n",
        "# Creating dataframe\n",
        "df = pd.DataFrame({\"CoronaData\": data})\n",
        " \n",
        "# Naming the columns\n",
        "df.index = ['TotalCases', ' Deaths', 'Recovered']\n",
        " \n",
        " \n",
        " \n",
        "# Exporting data into Excel\n",
        "df.to_csv('Corona_Data.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kkze6U_eZb4u",
        "outputId": "67e2fa3a-f7f6-4916-c2c8-7dc7e6e95f2e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['43,036,928 ', '521,723', '42,504,329']\n"
          ]
        }
      ]
    }
  ]
}